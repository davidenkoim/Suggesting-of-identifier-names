{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        return json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_stats(lexed, predictions, n=1):\n",
    "    '''\n",
    "        n -- number of predictions by which the true prediction is defined.\n",
    "    '''\n",
    "    assert lexed['left'] == predictions['left'], 'Predictions to wrong file!'\n",
    "    lexs, preds = lexed['right'], predictions['right'] \n",
    "    trues, total, mrr = 0., 0, 0.\n",
    "    for l, ps in zip(chain(*lexs), chain(*preds)):\n",
    "        if len(ps) != 0:\n",
    "            trues += 1 if l in ps[:n] else 0\n",
    "            total += 1\n",
    "            mrr += 1/(1 + ps.index(l)) if l in ps else 0\n",
    "    return trues, total, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_stats(lexed, predictions, top_n=1, bounds=None):\n",
    "    '''\n",
    "        top_n -- number of predictions by which the true prediction is defined.\n",
    "        bounds=(l,r) -- bounds in which total count of identifiers in a file has to lie.\n",
    "    '''\n",
    "    trues, total, mrr, n_files, avr_acc, avr_mrr = 0, 0, 0, 0, 0, 0\n",
    "    for lexs, preds in zip(lexed, predictions):\n",
    "        tr, tot, m = get_file_stats(lexs, preds, n=top_n)\n",
    "        if tot>0 and (bounds is None or bounds[0] <= tot <= bounds[1]):\n",
    "            avr_acc += tr/tot\n",
    "            avr_mrr += m/tot\n",
    "            trues += tr\n",
    "            mrr += m\n",
    "            total += tot\n",
    "            n_files += 1\n",
    "    print(f'Count of files: {n_files}')\n",
    "    print(f'Count of identifiers: {total}')\n",
    "    print(f'Top-{top_n} accuracy: {trues/total:.4f}')\n",
    "    print(f'MRR: {mrr/total:.4f}')\n",
    "    print('Leave-one-out CV')\n",
    "    print(f'Top-{top_n} accuracy: {avr_acc/n_files:.4f}')\n",
    "    print(f'MRR: {avr_mrr/n_files:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_for_files(lexed, predictions, top_n=1, bounds=None, all=False):\n",
    "    '''\n",
    "        Shows state for each file (10 files in a batch).\n",
    "        \n",
    "        top_n -- number of predictions by which the true prediction is defined.\n",
    "        bounds=(l,r) -- bounds in which total count of identifiers in a file has to lie.\n",
    "    '''\n",
    "    print(f'File id |  Count  |Accuracy {top_n}|  MRR  |')\n",
    "    print('--------|---------|----------|-------|')\n",
    "    k = 0\n",
    "    for i, (lexs, preds) in enumerate(zip(lexed, predictions)):\n",
    "        trues, total, mrr = get_file_stats(lexs, preds, n=top_n)\n",
    "        if bounds is None or bounds[0] <= total <= bounds[1]:\n",
    "            k += 1\n",
    "            if total == 0:\n",
    "                print(f'{i: <8}|0        |-         |-      |')\n",
    "            else:\n",
    "                print(f'{i: <8}|{total: <9}|{(trues/total): <10.4f}|{mrr/total: <7.4f}|')\n",
    "            if not all and k % 10 == 0 and input('Do you want more?[y]/n') in {'n', 'No', 'no', 'exit'}:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_project_stats(projectNames, top_n=1, bounds=None):\n",
    "    for projectName in projectNames:\n",
    "        lexed = read(\"cash/\" + projectName + \"/lexed.json\")\n",
    "        predictions = read(\"cash/\" + projectName + \"/predictions.json\")\n",
    "        print(f'{projectName:_^30}')\n",
    "        get_average_stats(lexed, predictions, top_n, bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Train on a project and self-test on each file in it. Self-testing means that before inference model forget about all tokens that it learned on the test file and only after that it makes predictions on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectNames = ['elasticsearch-master',\n",
    "                'cassandra-trunk',\n",
    "                'xmlgraphics-batik-trunk',\n",
    "                'ant-master']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____elasticsearch-master_____\n",
      "Count of files: 13364\n",
      "Count of identifiers: 2830079\n",
      "Top-1 accuracy: 0.4591\n",
      "MRR: 0.5291\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.5308\n",
      "MRR: 0.6040\n",
      "_______cassandra-trunk________\n",
      "Count of files: 2738\n",
      "Count of identifiers: 516216\n",
      "Top-1 accuracy: 0.3181\n",
      "MRR: 0.3746\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.4080\n",
      "MRR: 0.4670\n",
      "___xmlgraphics-batik-trunk____\n",
      "Count of files: 1479\n",
      "Count of identifiers: 180824\n",
      "Top-1 accuracy: 0.3045\n",
      "MRR: 0.3515\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.4817\n",
      "MRR: 0.5407\n",
      "__________ant-master__________\n",
      "Count of files: 1304\n",
      "Count of identifiers: 145884\n",
      "Top-1 accuracy: 0.3134\n",
      "MRR: 0.3612\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.4729\n",
      "MRR: 0.5249\n"
     ]
    }
   ],
   "source": [
    "get_average_project_stats(projectNames, top_n=1, bounds=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectName = 'elasticsearch-master'\n",
    "# projectName = 'cassandra-trunk'\n",
    "# projectName = 'ant-master'\n",
    "# projectName = 'xmlgraphics-batik-trunk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = read(\"cash/\" + projectName + \"/vocabulary.json\")\n",
    "lexed = read(\"cash/\" + projectName + \"/lexed.json\")\n",
    "identifiers = set(read(\"cash/\" + projectName + \"/identifiers.json\"))\n",
    "predictions = read(\"cash/\" + projectName + \"/predictions.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see more detailed information about each file in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File id |  Count  |Accuracy 1|  MRR  |\n",
      "--------|---------|----------|-------|\n",
      "0       |112      |0.5804    |0.6197 |\n",
      "1       |55       |0.5636    |0.5997 |\n",
      "2       |164      |0.5366    |0.6047 |\n",
      "3       |126      |0.6429    |0.7420 |\n",
      "4       |45       |0.7333    |0.7630 |\n",
      "5       |43       |0.7907    |0.8333 |\n",
      "6       |110      |0.3636    |0.4267 |\n",
      "7       |22       |0.3636    |0.4867 |\n",
      "8       |7        |0.2857    |0.2857 |\n",
      "9       |344      |0.1919    |0.2463 |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want more?[y]/n \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10      |107      |0.2243    |0.2644 |\n",
      "11      |68       |0.5882    |0.6495 |\n",
      "12      |447      |0.3423    |0.3792 |\n",
      "13      |139      |0.4748    |0.5091 |\n",
      "14      |54       |0.4444    |0.5160 |\n",
      "15      |315      |0.2698    |0.3158 |\n",
      "16      |211      |0.4313    |0.4904 |\n",
      "17      |43       |0.4651    |0.5035 |\n",
      "18      |103      |0.5243    |0.5843 |\n",
      "19      |7        |0.5714    |0.6633 |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want more?[y]/n n\n"
     ]
    }
   ],
   "source": [
    "get_stats_for_files(lexed, predictions, bounds=None, top_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151038, 50721)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary), len(identifiers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
