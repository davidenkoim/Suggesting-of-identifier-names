{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import os.path\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from copy import copy\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        return json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_stats(identifiers, n=1):\n",
    "    '''\n",
    "        n -- number of predictions by which the true prediction is defined.\n",
    "    '''\n",
    "    trues, mrr = 0., 0.\n",
    "    for i in identifiers:\n",
    "        gt = i['gt']\n",
    "        ps = [p['left'] for p in i['prediction']]\n",
    "        trues += 1 if gt in ps[:n] else 0\n",
    "        mrr += 1/(1 + ps.index(gt)) if gt in ps else 0\n",
    "    return trues, len(identifiers), mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_stats(files, top_n=1, bounds=None):\n",
    "    '''\n",
    "        top_n -- number of predictions by which the true prediction is defined.\n",
    "        bounds=(l,r) -- bounds in which total count of identifiers in a file has to lie.\n",
    "    '''\n",
    "    trues, total, mrr, n_files, avr_acc, avr_mrr = 0, 0, 0, 0, 0, 0\n",
    "    for identifiers in files.values():\n",
    "        tr, tot, m = get_file_stats(identifiers['identifiers'], n=top_n)\n",
    "        if tot>0 and (bounds is None or bounds[0] <= tot <= bounds[1]):\n",
    "            avr_acc += tr/tot\n",
    "            avr_mrr += m/tot\n",
    "            trues += tr\n",
    "            mrr += m\n",
    "            total += tot\n",
    "            n_files += 1\n",
    "    print(f'Count of files: {n_files}')\n",
    "    print(f'Count of identifiers: {total}')\n",
    "    print(f'Top-{top_n} accuracy: {trues/total:.4f}')\n",
    "    print(f'MRR: {mrr/total:.4f}')\n",
    "    print('Leave-one-out CV')\n",
    "    print(f'Top-{top_n} accuracy: {avr_acc/n_files:.4f}')\n",
    "    print(f'MRR: {avr_mrr/n_files:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_for_files(predictions, files, top_n=1,\n",
    "                        bounds=None,\n",
    "                        acc_bounds=None,\n",
    "                        mrr_bounds=None,\n",
    "                        path=None,\n",
    "                        all=False):\n",
    "    '''\n",
    "        Shows state for each file (10 files in a batch).\n",
    "        \n",
    "        top_n -- number of predictions by which the true prediction is defined.\n",
    "        bounds=(l,r) -- bounds in which total count of identifiers in a file has to lie.\n",
    "    '''\n",
    "    print(f'File id |N identifiers|Accuracy {top_n}|  MRR  |')\n",
    "    print('--------|-------------|----------|-------|')\n",
    "    k = 0\n",
    "    for i, file in enumerate(files):\n",
    "        trues, total, mrr = get_file_stats(predictions[file]['identifiers'], n=top_n)\n",
    "        acc, mrr = (trues/total, mrr/total) if total > 0 else (0, 0)\n",
    "        if (bounds is None or bounds[0] <= total <= bounds[1]) and (\n",
    "            acc_bounds is None or acc_bounds[0] <= acc <= acc_bounds[1]) and (\n",
    "            mrr_bounds is None or mrr_bounds[0] <= mrr <= mrr_bounds[1]):\n",
    "            k += 1\n",
    "            print(f'{i: <8}|{total: <13}|{acc: <10.4f}|{mrr: <7.4f}|')\n",
    "            if not all and k % 10 == 0 and input('Do you want more?[y]/n') in {'n', 'No', 'no', 'exit'}:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_files_with_stats(predictions, k,\n",
    "                                top_n=1,\n",
    "                                bounds=None,\n",
    "                                acc_bounds=None,\n",
    "                                mrr_bounds=None,\n",
    "                                path=None,\n",
    "                                all=False):\n",
    "    i = 0\n",
    "    files = list(predictions)\n",
    "    rnd.shuffle(files)\n",
    "    for file in files:\n",
    "        trues, total, mrr = get_file_stats(predictions[file]['identifiers'], n=top_n)\n",
    "        acc, mrr = (trues/total, mrr/total) if total > 0 else (0, 0)\n",
    "        if (bounds is None or bounds[0] <= total <= bounds[1]) and (\n",
    "            acc_bounds is None or acc_bounds[0] <= acc <= acc_bounds[1]) and (\n",
    "            mrr_bounds is None or mrr_bounds[0] <= mrr <= mrr_bounds[1]):\n",
    "            yield file\n",
    "            i += 1\n",
    "            if i == k: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_project_stats(trainingType, projectNames, top_n=1, bounds=None):\n",
    "    print(f'{trainingType: ^30}')\n",
    "    for projectName in projectNames:\n",
    "        predictions = read(trainingType + \"/predictions_\" + projectName + \".json\")\n",
    "        print(f'{projectName:_^30}')\n",
    "        get_average_stats(predictions, top_n, bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Train on a project and self-test on each file in it. Self-testing means that before inference model forget about all tokens that it learned on the test file and only after that it makes predictions on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectNames = ['elasticsearch-master',\n",
    "                'cassandra-trunk',\n",
    "                'xmlgraphics-batik-trunk',\n",
    "                'ant-master']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         selfTraining         \n",
      "_____elasticsearch-master_____\n",
      "Count of files: 12528\n",
      "Count of identifiers: 349602\n",
      "Top-1 accuracy: 0.6119\n",
      "MRR: 0.6757\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.4911\n",
      "MRR: 0.5459\n",
      "_______cassandra-trunk________\n",
      "Count of files: 2610\n",
      "Count of identifiers: 81027\n",
      "Top-1 accuracy: 0.6137\n",
      "MRR: 0.6863\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.5237\n",
      "MRR: 0.5829\n",
      "___xmlgraphics-batik-trunk____\n",
      "Count of files: 1383\n",
      "Count of identifiers: 33053\n",
      "Top-1 accuracy: 0.6182\n",
      "MRR: 0.6918\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.4954\n",
      "MRR: 0.5546\n",
      "__________ant-master__________\n",
      "Count of files: 1127\n",
      "Count of identifiers: 23013\n",
      "Top-1 accuracy: 0.4648\n",
      "MRR: 0.5390\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.3762\n",
      "MRR: 0.4336\n"
     ]
    }
   ],
   "source": [
    "get_average_project_stats('selfTraining', projectNames, top_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         selfTesting          \n",
      "_____elasticsearch-master_____\n",
      "Count of files: 12528\n",
      "Count of identifiers: 349602\n",
      "Top-1 accuracy: 0.5171\n",
      "MRR: 0.5844\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.6231\n",
      "MRR: 0.6839\n",
      "_______cassandra-trunk________\n",
      "Count of files: 2610\n",
      "Count of identifiers: 81027\n",
      "Top-1 accuracy: 0.4367\n",
      "MRR: 0.5033\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.5332\n",
      "MRR: 0.5946\n",
      "___xmlgraphics-batik-trunk____\n",
      "Count of files: 1383\n",
      "Count of identifiers: 33053\n",
      "Top-1 accuracy: 0.5266\n",
      "MRR: 0.5806\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.6884\n",
      "MRR: 0.7334\n",
      "__________ant-master__________\n",
      "Count of files: 1127\n",
      "Count of identifiers: 23013\n",
      "Top-1 accuracy: 0.3810\n",
      "MRR: 0.4490\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.5016\n",
      "MRR: 0.5666\n"
     ]
    }
   ],
   "source": [
    "get_average_project_stats('selfTesting', projectNames, top_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    selfTestingIdentifier     \n",
      "_____elasticsearch-master_____\n",
      "Count of files: 12528\n",
      "Count of identifiers: 349602\n",
      "Top-1 accuracy: 0.6678\n",
      "MRR: 0.7317\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.6977\n",
      "MRR: 0.7579\n",
      "_______cassandra-trunk________\n",
      "Count of files: 2610\n",
      "Count of identifiers: 81027\n",
      "Top-1 accuracy: 0.6289\n",
      "MRR: 0.6979\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.6511\n",
      "MRR: 0.7149\n",
      "___xmlgraphics-batik-trunk____\n",
      "Count of files: 1383\n",
      "Count of identifiers: 33053\n",
      "Top-1 accuracy: 0.7055\n",
      "MRR: 0.7639\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.7501\n",
      "MRR: 0.7994\n",
      "__________ant-master__________\n",
      "Count of files: 1127\n",
      "Count of identifiers: 23013\n",
      "Top-1 accuracy: 0.5450\n",
      "MRR: 0.6193\n",
      "Leave-one-out CV\n",
      "Top-1 accuracy: 0.5907\n",
      "MRR: 0.6602\n"
     ]
    }
   ],
   "source": [
    "get_average_project_stats('selfTestingIdentifier', projectNames, top_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingType = 'selfTestingIdentifier'\n",
    "\n",
    "# projectName = 'elasticsearch-master'\n",
    "projectName = 'cassandra-trunk'\n",
    "# projectName = 'ant-master'\n",
    "# projectName = 'xmlgraphics-batik-trunk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = read(trainingType + \"/predictions_\" + projectName + \".json\")\n",
    "files = list(predictions.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see more detailed information about each file in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File id |N identifiers|Accuracy 1|  MRR  |\n",
      "--------|-------------|----------|-------|\n",
      "48      |222          |0.7973    |0.8381 |\n",
      "111     |240          |0.7792    |0.8412 |\n",
      "204     |201          |0.7363    |0.7814 |\n",
      "255     |203          |0.5271    |0.6485 |\n",
      "495     |314          |0.5382    |0.6199 |\n",
      "663     |224          |0.3125    |0.3551 |\n",
      "717     |200          |0.4900    |0.6161 |\n",
      "897     |282          |0.5816    |0.6714 |\n",
      "962     |370          |0.5838    |0.6589 |\n",
      "1042    |219          |0.9269    |0.9568 |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want more?[y]/n \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117    |329          |0.5653    |0.6525 |\n",
      "1131    |337          |0.7893    |0.8462 |\n",
      "1152    |229          |0.6114    |0.6727 |\n",
      "1180    |298          |0.7114    |0.7626 |\n",
      "1209    |449          |0.7906    |0.8499 |\n",
      "1238    |932          |0.5440    |0.6176 |\n",
      "1355    |292          |0.5788    |0.6657 |\n",
      "1483    |266          |0.7368    |0.8057 |\n",
      "1568    |307          |0.4202    |0.5248 |\n",
      "1585    |202          |0.8762    |0.9089 |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want more?[y]/n \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589    |309          |0.6990    |0.7657 |\n",
      "1628    |218          |0.6927    |0.7819 |\n",
      "1810    |222          |0.7973    |0.8391 |\n",
      "1893    |290          |0.7103    |0.7749 |\n",
      "1895    |290          |0.5103    |0.5851 |\n",
      "1934    |356          |0.6152    |0.7250 |\n",
      "1976    |467          |0.5824    |0.6565 |\n",
      "2057    |204          |0.5882    |0.6541 |\n",
      "2110    |357          |0.6303    |0.7098 |\n",
      "2137    |452          |0.5597    |0.6503 |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want more?[y]/n \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2336    |256          |0.9766    |0.9779 |\n",
      "2346    |544          |0.6011    |0.6852 |\n",
      "2398    |268          |0.7500    |0.8271 |\n",
      "2410    |273          |0.6300    |0.6908 |\n",
      "2670    |281          |0.6690    |0.7290 |\n"
     ]
    }
   ],
   "source": [
    "get_stats_for_files(predictions, files, bounds=(200, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2738"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make some files with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair2tuple(pair):\n",
    "    return (pair['left'], pair['right'])\n",
    "\n",
    "def pairs2tuples(pairs):\n",
    "    return [pair2tuple(pair) for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingType = 'selfTestingIdentifier'\n",
    "projectName = 'ant-master'\n",
    "predictions = read(trainingType + \"/predictions_\" + projectName + \".json\")\n",
    "os.makedirs('predicted files/' + projectName, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file_with_predictions(path, projectName, trainingType, predictions):\n",
    "    path = os.path.abspath(path)\n",
    "    new_file = ''\n",
    "    new_file += f'// Type of training: {trainingType}\\n'\n",
    "    new_file += f'// Path to file: {path}\\n'\n",
    "    identifiers = predictions[path]['identifiers']\n",
    "    trues, total, mrr = get_file_stats(identifiers)\n",
    "    if total == 0:\n",
    "        new_file += f'// Number of identifiers: {total}\\n'\n",
    "    else:\n",
    "        new_file += f'// Number of identifiers: {total}\\tAccuracy: {(trues/total*100.):.2f}%\\tMRR: {mrr/total*100.:.2f}%\\n'\n",
    "        new_file += '// True \\tRank of true in predictions : [(predicted token, probability of a token), ...]\\n\\n'\n",
    "    with open(path, 'r') as f:\n",
    "        file_lines = f.readlines()\n",
    "        identifiers_per_line = [[] for _ in range(len(file_lines))]\n",
    "        for identifier in identifiers:\n",
    "            line = identifier['range']['begin']['line'] - 1\n",
    "            identifiers_per_line[line].append(identifier)\n",
    "        for i, line in enumerate(file_lines):\n",
    "            new_file += line\n",
    "            for j, identifier in enumerate(identifiers_per_line[i]):\n",
    "                prediction_with_prob = pairs2tuples(identifier['prediction'])\n",
    "                prediction = list(zip(*prediction_with_prob))[0]\n",
    "                gt = identifier['gt']\n",
    "                gt_i = prediction.index(gt) if gt in prediction else 'No'\n",
    "                new_file += f'// {gt: <20} {gt_i}\\t: {prediction_with_prob}\\n'\n",
    "    with open(os.path.join('predicted_files/' + projectName, os.path.basename(path)), 'w') as f:\n",
    "        f.write(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_predictions(projectName, trainingType='selfTestingIdentifier', n=10, **kargs):\n",
    "    print(f'File name                                    |N identifiers|Accuracy  |  MRR  |')\n",
    "    print('---------------------------------------------|-------------|----------|-------|')\n",
    "    predictions = read(trainingType + \"/predictions_\" + projectName + \".json\")\n",
    "    os.makedirs('predicted_files/' + projectName, exist_ok=True)\n",
    "    files = rnd.sample(list(predictions), n)\n",
    "    for file in get_random_files_with_stats(predictions, n, **kargs):\n",
    "        trues, total, mrr = get_file_stats(predictions[file]['identifiers'])\n",
    "        save_file_with_predictions(file, projectName, trainingType, predictions)\n",
    "        if total == 0:\n",
    "            print(f'{os.path.basename(file): <45}|0            |-         |-      |')\n",
    "        else:\n",
    "            print(f'{os.path.basename(file): <45}|{total: <13}|{(trues/total): <10.4f}|{mrr/total: <7.4f}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              elasticsearch-master                              \n",
      "File name                                    |N identifiers|Accuracy  |  MRR  |\n",
      "---------------------------------------------|-------------|----------|-------|\n",
      "TransportGetAutoFollowPatternAction.java     |17           |0.8235    |0.8603 |\n",
      "ActionListener.java                          |59           |0.5593    |0.6416 |\n",
      "SizeMappingIT.java                           |16           |0.5625    |0.6458 |\n",
      "SimpleChecksAdapter.java                     |14           |0.5714    |0.5893 |\n",
      "AttachmentProcessorTests.java                |54           |0.7037    |0.7575 |\n",
      "TransportAddVotingConfigExclusionsAction.java|37           |0.6757    |0.7032 |\n",
      "MissingAggregator.java                       |13           |0.7692    |0.8654 |\n",
      "DataCounts.java                              |17           |0.8824    |0.9314 |\n",
      "ValidateMappingRequestPluginIT.java          |16           |0.9375    |0.9688 |\n",
      "SingleOrdinalsTests.java                     |14           |0.4286    |0.5786 |\n",
      "                                cassandra-trunk                                 \n",
      "File name                                    |N identifiers|Accuracy  |  MRR  |\n",
      "---------------------------------------------|-------------|----------|-------|\n",
      "TombstoneHistogram.java                      |19           |0.4211    |0.5500 |\n",
      "AbstractCommitLogServiceTest.java            |36           |0.8056    |0.8333 |\n",
      "Connection.java                              |106          |0.6887    |0.7472 |\n",
      "LoaderOptions.java                           |57           |0.5439    |0.5927 |\n",
      "MethodComparator.java                        |23           |0.3478    |0.4638 |\n",
      "AbstractPatriciaTrie.java                    |84           |0.5952    |0.6966 |\n",
      "TriggerExecutor.java                         |39           |0.3846    |0.4701 |\n",
      "BatchlogResponseHandler.java                 |10           |0.7000    |0.7500 |\n",
      "DynamicEndpointSnitchTest.java               |18           |0.4444    |0.6005 |\n",
      "LZ4Compressor.java                           |14           |0.5000    |0.7024 |\n",
      "                            xmlgraphics-batik-trunk                             \n",
      "File name                                    |N identifiers|Accuracy  |  MRR  |\n",
      "---------------------------------------------|-------------|----------|-------|\n",
      "DOMUIEvent.java                              |17           |0.8824    |0.8941 |\n",
      "SVGUserAgentAdapter.java                     |29           |1.0000    |1.0000 |\n",
      "BaselineShiftManager.java                    |18           |0.7222    |0.7639 |\n",
      "ScriptingEnvironment.java                    |138          |0.7246    |0.8019 |\n",
      "FontFace.java                                |51           |0.7059    |0.7827 |\n",
      "SVGGVTFont.java                              |139          |0.7122    |0.7528 |\n",
      "SVGFontUtilities.java                        |48           |0.3958    |0.4781 |\n",
      "TileRable8Bit.java                           |106          |0.4811    |0.5374 |\n",
      "BridgeContext.java                           |244          |0.6475    |0.7292 |\n",
      "ExternalResourcesTest.java                   |47           |0.7021    |0.7580 |\n",
      "                                   ant-master                                   \n",
      "File name                                    |N identifiers|Accuracy  |  MRR  |\n",
      "---------------------------------------------|-------------|----------|-------|\n",
      "PropertyFileTest.java                        |19           |0.4211    |0.5707 |\n",
      "JDBCTask.java                                |29           |0.5517    |0.6015 |\n",
      "MailMessageTest.java                         |58           |0.8276    |0.8506 |\n",
      "ZipEncodingTest.java                         |10           |0.2000    |0.3394 |\n",
      "CVSPass.java                                 |12           |0.3333    |0.4861 |\n",
      "JUnitLauncherTask.java                       |61           |0.4754    |0.5390 |\n",
      "ModifiedSelector.java                        |77           |0.3377    |0.4111 |\n",
      "MockBuildListener.java                       |12           |0.7500    |0.7619 |\n",
      "XmlProperty.java                             |69           |0.4058    |0.5307 |\n",
      "XSLTProcess.java                             |122          |0.4426    |0.5338 |\n"
     ]
    }
   ],
   "source": [
    "for projectName in projectNames:\n",
    "    print(f'{projectName: ^80}')\n",
    "    make_random_predictions(projectName, bounds=(10, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
